{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsZ4+Wmo5hkNYF69z2LdvD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guifav/roger/blob/main/Roger%20-%20AI_Agente_Escritor_de_Blog%20(Com%20SERPER).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8_To7XLFnMD1",
        "outputId": "db5a0350-5a99-4bf0-e590-6773410d8381"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detectado ambiente Google Colab.\n",
            "Para configurar suas chaves API de forma segura, execute a fun√ß√£o setup_api_keys() primeiro.\n",
            "\n",
            "===== üìù GERADOR DE ARTIGOS DE BLOG OTIMIZADOS PARA SEO =====\n",
            "\n",
            "‚úÖ Chave API OpenAI obtida com sucesso do armazenamento seguro do Colab.\n",
            "\n",
            "Deseja usar a busca na internet para enriquecer o conte√∫do? (s/n): s\n",
            "‚úÖ Chave API Serper obtida com sucesso do armazenamento seguro do Colab.\n",
            "\n",
            "Selecione o modelo da OpenAI:\n",
            "\n",
            "Reasoning models:\n",
            "1. o3-mini - Fast, flexible, intelligent reasoning model\n",
            "2. o1 - High-intelligence reasoning model\n",
            "3. o1-mini - A faster, more affordable reasoning model than o1\n",
            "4. o1-pro - A version of o1 with more compute for better responses\n",
            "\n",
            "Flagship chat models:\n",
            "5. GPT-4.5 Preview - Largest and most capable GPT model\n",
            "6. GPT-4o - Fast, intelligent, flexible GPT model\n",
            "7. ChatGPT-4o - GPT-4o model used in ChatGPT\n",
            "\n",
            "Cost-optimized models:\n",
            "8. GPT-4o mini - Fast, affordable small model for focused tasks\n",
            "\n",
            "Older GPT models:\n",
            "9. GPT-4 Turbo - An older high-intelligence GPT model\n",
            "10. GPT-4 - An older high-intelligence GPT model\n",
            "11. GPT-3.5 Turbo - Legacy GPT model for cheaper chat and non-chat tasks\n",
            "\n",
            "Escolha o n√∫mero correspondente (padr√£o: 11): 5\n",
            "Modelo selecionado: gpt-4.5-preview\n",
            "‚úÖ Busca na internet habilitada usando API Serper.\n",
            "\n",
            "Qual √© o t√≥pico principal do artigo? open source llm\n",
            "\n",
            "Insira as palavras-chave para SEO (separadas por v√≠rgula): \n",
            "openai, meta, google, hugging face, elon musk\n",
            "\n",
            "Selecione o tom do artigo:\n",
            "1. informativo\n",
            "2. persuasivo\n",
            "3. conversacional\n",
            "4. t√©cnico\n",
            "5. inspirador\n",
            "Escolha o n√∫mero correspondente: 5\n",
            "\n",
            "Criando esbo√ßo do artigo...\n",
            "üîç Buscando informa√ß√µes sobre: 'open source llm openai meta google hugging face elon musk'\n",
            "\n",
            "===== ESBO√áO DO ARTIGO =====\n",
            "üìå T√≠tulo: Open Source LLM: O Futuro Aberto da Intelig√™ncia Artificial\n",
            "üìù Meta Descri√ß√£o: Descubra como os modelos open source LLM est√£o revolucionando a IA, com iniciativas de OpenAI, Meta, Google, Hugging Face e Elon Musk.\n",
            "\n",
            "üìë Se√ß√µes:\n",
            "  1. Introdu√ß√£o\n",
            "     ‚Ä¢ Breve apresenta√ß√£o do conceito de modelos de linguagem de grande porte (LLM)\n",
            "     ‚Ä¢ Por que o open source √© essencial para a democratiza√ß√£o da IA\n",
            "     ‚Ä¢ Objetivos do artigo e men√ß√£o √†s principais empresas e personalidades envolvidas: OpenAI, Meta, Google, Hugging Face e Elon Musk\n",
            "  2. O que s√£o Open Source LLM e por que s√£o importantes?\n",
            "     ‚Ä¢ Defini√ß√£o clara e acess√≠vel de open source LLM\n",
            "     ‚Ä¢ Compara√ß√£o entre modelos propriet√°rios e open source\n",
            "     ‚Ä¢ Benef√≠cios da transpar√™ncia, acessibilidade e colabora√ß√£o\n",
            "     ‚Ä¢ Como o open source facilita a inova√ß√£o acelerada em IA\n",
            "  3. Iniciativas Open Source das Gigantes da Tecnologia\n",
            "     ‚Ä¢ Como a Meta est√° impulsionando a IA aberta com modelos como o LLaMA\n",
            "     ‚Ä¢ A contribui√ß√£o do Google com projetos como BERT e T5\n",
            "     ‚Ä¢ OpenAI e seu hist√≥rico em open source: GPT-2 e Whisper\n",
            "     ‚Ä¢ Hugging Face: a comunidade que transformou o acesso a modelos LLM\n",
            "  4. Elon Musk e sua vis√£o sobre IA aberta e segura\n",
            "     ‚Ä¢ Participa√ß√£o inicial de Elon Musk na OpenAI e sua vis√£o original\n",
            "     ‚Ä¢ Preocupa√ß√µes de Musk sobre seguran√ßa e controle da IA\n",
            "     ‚Ä¢ Como a abordagem open source pode ajudar na cria√ß√£o de IA √©tica e segura\n",
            "  5. Benef√≠cios e desafios dos modelos LLM open source\n",
            "     ‚Ä¢ Vantagens como redu√ß√£o de custos, flexibilidade e colabora√ß√£o\n",
            "     ‚Ä¢ Principais desafios como seguran√ßa, vi√©s e desinforma√ß√£o\n",
            "     ‚Ä¢ Estudos de caso mostrando como empresas e comunidades superaram desafios\n",
            "  6. Casos de sucesso de projetos open source LLM\n",
            "     ‚Ä¢ Projetos not√°veis como BLOOM, Falcon e GPT-J\n",
            "     ‚Ä¢ Impactos positivos na educa√ß√£o, pesquisa e neg√≥cios\n",
            "     ‚Ä¢ Hist√≥rias inspiradoras de inova√ß√£o comunit√°ria\n",
            "  7. Como voc√™ pode contribuir com projetos open source LLM\n",
            "     ‚Ä¢ Plataformas populares como Hugging Face e GitHub\n",
            "     ‚Ä¢ Como come√ßar a desenvolver ou utilizar um modelo open source\n",
            "     ‚Ä¢ Comunidades e recursos √∫teis para iniciantes\n",
            "  8. Conclus√£o\n",
            "     ‚Ä¢ Resumo das principais vantagens e desafios do open source LLM\n",
            "     ‚Ä¢ A import√¢ncia da colabora√ß√£o global para o futuro da IA\n",
            "     ‚Ä¢ Mensagem inspiradora ressaltando o potencial transformador de uma IA aberta e transparente\n",
            "  9. Chamada para A√ß√£o\n",
            "     ‚Ä¢ Convite para explorar comunidades como Hugging Face e GitHub\n",
            "     ‚Ä¢ Incentivar o leitor a contribuir com projetos open source LLM\n",
            "     ‚Ä¢ Sugest√£o de compartilhamento do artigo para ampliar o conhecimento e consci√™ncia sobre IA aberta\n",
            "\n",
            "Deseja gerar o artigo completo com base neste esbo√ßo? (s/n): s\n",
            "Gerando artigo completo...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [08:22<00:00, 55.82s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== AN√ÅLISE DO ARTIGO =====\n",
            "üìä Contagem de palavras: 4786 (m√≠nimo: 2000)\n",
            "üîç Pontua√ß√£o SEO: 79.67/100\n",
            "üìñ Pontua√ß√£o de legibilidade: 77.53/100\n",
            "\n",
            "üìà Densidade de palavras-chave:\n",
            "  ‚úÖ 'openai': 27 ocorr√™ncias (0.56%)\n",
            "  ‚úÖ 'meta': 28 ocorr√™ncias (0.59%)\n",
            "  ‚úÖ 'google': 24 ocorr√™ncias (0.5%)\n",
            "  ‚úÖ 'hugging face': 34 ocorr√™ncias (0.71%)\n",
            "  ‚ö†Ô∏è 'elon musk': 15 ocorr√™ncias (0.31%)\n",
            "\n",
            "===== PR√âVIA DO ARTIGO =====\n",
            "# Open Source LLM: O Futuro Aberto da Intelig√™ncia Artificial\n",
            "\n",
            "## Introdu√ß√£o\n",
            "\n",
            "## Introdu√ß√£o\n",
            "\n",
            "Nos √∫ltimos anos, a intelig√™ncia artificial (IA) deu um salto impressionante gra√ßas ao surgimento dos Modelos de Linguagem de Grande Porte, conhecidos como LLM (do ingl√™s, Large Language Models). Esses modelos s√£o sistemas de IA treinados em imensas quantidades de texto para gerar respostas coerentes, realistas e contextualmente relevantes. Exemplos famosos incluem o GPT-4 da OpenAI, LaMDA do Google e LLaMA da Meta, que t√™m transformado significativamente a forma como interagimos com tecnologia no dia a dia.\n",
            "\n",
            "Essencialmente, modelos de linguagem como esses s√£o projetados para entender e gerar linguagem humana com alto grau de precis√£o e naturalidade. Isso possibilita diversas aplica√ß√µes, desde assistentes virtuais avan√ßados e chatbots inteligentes at√© ferramentas sofisticadas de escrita criativa, educa√ß√£o e pesquisa cient√≠fica. Por exemplo, o ChatGPT da OpenAI j√° √© amplamente utilizado no atendimento ao cliente, produ√ß√£o de conte√∫do online e at√© no desenvolvimento de softwares.\n",
            "\n",
            "No entanto, apesar das incont√°veis possibilidades oferecidas pelos LLMs, uma quest√£o importante persiste: como garantir que essa tecnologia revolucion√°ria seja acess√≠vel a todos? √â nesse ponto que entra o conceito de open source, ou c√≥digo aberto. Ao compartilhar livremente o c√≥digo e os modelos, empresas e pesquisadores podem colaborar de forma transparente, acelerando o avan√ßo tecnol√≥gico e permitindo que mais pessoas participem do desenvolvimento da IA. Nesse contexto, empresas como a Hugging Face t√™m sido fundamentais, oferecendo plataformas abertas e ferramentas gratuitas que democratizam o acesso e facilitam experimentos com modelos de diferentes tamanhos e capacidades.\n",
            "\n",
            "A import√¢ncia da abordagem open source fica clara quando analisamos os esfor√ßos recentes das grandes empresas de tecnologia. Enquanto organiza√ß√µes como OpenAI e Google seguem abordagens mais fechadas em rela√ß√£o aos seus modelos mais avan√ßados, a Meta optou por liberar seu modelo LLaMA ao p√∫blico, estimulando uma verdadeira onda de inova√ß√£o colaborativa entre desenvolvedores independentes, startups e pesquisadores acad√™micos. Essa estrat√©gia aberta n√£o apenas impulsiona o progresso tecnol√≥gico, mas tamb√©m reduz barreiras econ√¥micas e t√©cnicas para a implementa√ß√£o pr√°tica da IA.\n",
            "\n",
            "Al√©m disso, personalidades influentes como Elon Musk t√™m defendido abertamente a necessidade de maior transpar√™ncia e abertura no desenvolvimento da intelig√™ncia artificial. Musk, conhecido por suas declara√ß√µes pol√™micas e vis√£o futurista, argumenta que o open source √© essencial n√£o apenas para evitar monop√≥lios tecnol√≥gicos, mas tamb√©m para garantir que a IA seja desenvolvida com √©tica e responsabilidade social, de forma a beneficiar toda a humanidade.\n",
            "\n",
            "Neste artigo, exploraremos profundamente como os modelos de linguagem de grande porte t√™m evolu√≠do, qual o papel crucial desempenhado pelo open source na democratiza√ß√£o da IA e como grandes organiza√ß√µes e l√≠deres influentes como OpenAI, Meta, Google, Hugging Face e Elon Musk est√£o moldando o futuro dessa tecnologia promissora.\n",
            "\n",
            "## O que s√£o Open Source LLM e por que s√£o importantes?\n",
            "\n",
            "...\n",
            "\n",
            "Deseja salvar o artigo? Escolha o formato:\n",
            "1. Markdown (.md)\n",
            "2. HTML (.html)\n",
            "3. Texto (.txt)\n",
            "4. Mostrar artigo completo na tela\n",
            "5. N√£o salvar\n",
            "Escolha o n√∫mero correspondente: 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_94490e21-217e-434e-a6da-ab719b019f7c\", \"open_source_llm_o_futuro_aberto_da_intelig\\u00eancia_artificial.html\", 35923)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo 'open_source_llm_o_futuro_aberto_da_intelig√™ncia_artificial.html' criado e dispon√≠vel para download.\n",
            "\n",
            "‚úÖ Opera√ß√£o conclu√≠da!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "from datetime import datetime\n",
        "from IPython.display import HTML, display, Markdown\n",
        "\n",
        "# Verificar se estamos no ambiente do Google Colab\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    from google.colab import files\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Instala√ß√£o das bibliotecas necess√°rias\n",
        "try:\n",
        "    from openai import OpenAI\n",
        "    from nltk.tokenize import word_tokenize\n",
        "    from nltk.corpus import stopwords\n",
        "except ImportError:\n",
        "    !pip install openai==1.3.0 nltk tqdm pandas requests\n",
        "    from openai import OpenAI\n",
        "    from nltk.tokenize import word_tokenize\n",
        "    from nltk.corpus import stopwords\n",
        "\n",
        "# Download dos pacotes NLTK necess√°rios\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Garantir que o modelo para o portugu√™s est√° dispon√≠vel\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt/portuguese.pickle')\n",
        "except LookupError:\n",
        "    # Tenta baixar o pacote espec√≠fico para portugu√™s\n",
        "    nltk.download('punkt', download_dir='/root/nltk_data')\n",
        "\n",
        "    # Caso ainda ocorra erro, usaremos o tokenizador b√°sico\n",
        "    print(\"Aviso: Usando tokenizador b√°sico para portugu√™s.\")\n",
        "\n",
        "# Classe SerperSearchAPI implementada anteriormente\n",
        "class SerperSearchAPI:\n",
        "    \"\"\"Classe para realizar buscas na internet usando a API Serper.\"\"\"\n",
        "\n",
        "    def __init__(self, api_key=None):\n",
        "        \"\"\"\n",
        "        Inicializa a API Serper.\n",
        "\n",
        "        Args:\n",
        "            api_key (str, optional): Chave da API Serper.\n",
        "        \"\"\"\n",
        "        self.api_key = api_key\n",
        "        self.base_url = \"https://google.serper.dev/search\"\n",
        "        self.headers = None\n",
        "\n",
        "    def configure_api(self):\n",
        "        \"\"\"Configura a API do Serper.\"\"\"\n",
        "        if not self.api_key:\n",
        "            # Verifica se estamos no Google Colab e tenta obter a chave do userdata\n",
        "            if IN_COLAB:\n",
        "                try:\n",
        "                    self.api_key = userdata.get('SERPER_API_KEY')\n",
        "                    print(\"‚úÖ Chave API Serper obtida com sucesso do armazenamento seguro do Colab.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è N√£o foi poss√≠vel obter a chave Serper API do armazenamento seguro: {str(e)}\")\n",
        "                    print(\"Para configurar uma chave secreta no Google Colab:\")\n",
        "                    print(\"1. No menu lateral, clique em 'üîë' (Secrets)\")\n",
        "                    print(\"2. Adicione uma nova chave secreta com nome 'SERPER_API_KEY' e seu valor\")\n",
        "                    self.api_key = input(\"Digite sua chave de API Serper manualmente: \")\n",
        "            else:\n",
        "                self.api_key = input(\"Digite sua chave de API Serper: \")\n",
        "\n",
        "        self.headers = {\n",
        "            \"X-API-KEY\": self.api_key,\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "\n",
        "    def search(self, query, num_results=5):\n",
        "        \"\"\"\n",
        "        Realiza uma busca com a query fornecida.\n",
        "\n",
        "        Args:\n",
        "            query (str): Query de busca\n",
        "            num_results (int): N√∫mero de resultados a retornar\n",
        "\n",
        "        Returns:\n",
        "            dict: Resultados da busca ou erro\n",
        "        \"\"\"\n",
        "        if not self.headers:\n",
        "            self.configure_api()\n",
        "\n",
        "        payload = {\n",
        "            \"q\": query,\n",
        "            \"num\": num_results\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                self.base_url,\n",
        "                headers=self.headers,\n",
        "                json=payload\n",
        "            )\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                return response.json()\n",
        "            else:\n",
        "                return {\n",
        "                    \"error\": f\"Erro na busca: {response.status_code}\",\n",
        "                    \"details\": response.text\n",
        "                }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\"error\": f\"Erro ao realizar a busca: {str(e)}\"}\n",
        "\n",
        "    def extract_search_results(self, results):\n",
        "      \"\"\"\n",
        "      Extrai informa√ß√µes relevantes dos resultados de busca.\n",
        "\n",
        "      Args:\n",
        "          results (dict): Resultados da busca\n",
        "\n",
        "      Returns:\n",
        "          list: Lista com informa√ß√µes relevantes extra√≠das\n",
        "      \"\"\"\n",
        "      if isinstance(results, dict) and \"error\" in results:\n",
        "          return [{\"title\": \"Erro na busca\", \"snippet\": results[\"error\"], \"type\": \"error\"}]\n",
        "\n",
        "      extracted = []\n",
        "\n",
        "      # Resultados org√¢nicos\n",
        "      if isinstance(results, dict) and \"organic\" in results:\n",
        "          for item in results[\"organic\"]:\n",
        "              extracted.append({\n",
        "                  \"title\": item.get(\"title\", \"\"),\n",
        "                  \"link\": item.get(\"link\", \"\"),\n",
        "                  \"snippet\": item.get(\"snippet\", \"\"),\n",
        "                  \"type\": \"organic\"\n",
        "              })\n",
        "\n",
        "      # Knowledge graph\n",
        "      if isinstance(results, dict) and \"knowledgeGraph\" in results:\n",
        "          kg = results[\"knowledgeGraph\"]\n",
        "          extracted.append({\n",
        "              \"title\": kg.get(\"title\", \"\"),\n",
        "              \"type\": kg.get(\"type\", \"Informa√ß√£o\"),\n",
        "              \"description\": kg.get(\"description\", \"\"),\n",
        "              \"type\": \"knowledge\"\n",
        "          })\n",
        "\n",
        "      # Resultados de not√≠cias\n",
        "      if isinstance(results, dict) and \"news\" in results:\n",
        "          for item in results[\"news\"]:\n",
        "              extracted.append({\n",
        "                  \"title\": item.get(\"title\", \"\"),\n",
        "                  \"link\": item.get(\"link\", \"\"),\n",
        "                  \"snippet\": item.get(\"snippet\", \"\"),\n",
        "                  \"date\": item.get(\"date\", \"\"),\n",
        "                  \"type\": \"news\"\n",
        "              })\n",
        "\n",
        "      return extracted\n",
        "\n",
        "    def format_search_results_for_openai(self, results, max_results=5):\n",
        "      \"\"\"\n",
        "      Formata os resultados da busca para uso com a OpenAI.\n",
        "\n",
        "      Args:\n",
        "          results (list): Lista de resultados extra√≠dos\n",
        "          max_results (int): N√∫mero m√°ximo de resultados a formatar\n",
        "\n",
        "      Returns:\n",
        "          str: Texto formatado com os resultados\n",
        "      \"\"\"\n",
        "      if not results:\n",
        "          return \"Nenhum resultado encontrado.\"\n",
        "\n",
        "      if isinstance(results, list) and len(results) > 0 and \"type\" in results[0] and results[0][\"type\"] == \"error\":\n",
        "          return f\"Erro na busca: {results[0]['snippet']}\"\n",
        "\n",
        "      formatted = \"### Resultados da pesquisa\\n\\n\"\n",
        "\n",
        "      # Limitando o n√∫mero de resultados\n",
        "      results = results[:max_results]\n",
        "\n",
        "      for i, item in enumerate(results, 1):\n",
        "          if item[\"type\"] == \"organic\" or item[\"type\"] == \"news\":\n",
        "              formatted += f\"{i}. **{item['title']}**\\n\"\n",
        "              formatted += f\"   - Link: {item.get('link', 'N/A')}\\n\"\n",
        "              formatted += f\"   - Snippet: {item.get('snippet', 'N/A')}\\n\"\n",
        "              if \"date\" in item and item[\"date\"]:\n",
        "                  formatted += f\"   - Data: {item['date']}\\n\"\n",
        "              formatted += \"\\n\"\n",
        "          elif item[\"type\"] == \"knowledge\":\n",
        "              formatted += f\"{i}. **{item['title']}** ({item.get('type', 'N/A')})\\n\"\n",
        "              formatted += f\"   - Descri√ß√£o: {item.get('description', 'N/A')}\\n\\n\"\n",
        "\n",
        "      formatted += f\"Resultados obtidos em {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\\n\"\n",
        "\n",
        "      return formatted\n",
        "\n",
        "class BlogArticleGenerator:\n",
        "    def __init__(self, openai_api_key=None, serper_api_key=None, model=\"gpt-3.5-turbo\"):\n",
        "        \"\"\"\n",
        "        Inicializa o gerador de artigos para blog.\n",
        "\n",
        "        Args:\n",
        "            openai_api_key (str, optional): Chave da API OpenAI.\n",
        "            serper_api_key (str, optional): Chave da API Serper para busca na internet.\n",
        "            model (str): Modelo da OpenAI a ser usado.\n",
        "        \"\"\"\n",
        "        self.openai_api_key = openai_api_key\n",
        "        self.serper_api_key = serper_api_key\n",
        "        self.min_word_count = 2000\n",
        "        self.model = model\n",
        "        self.client = None\n",
        "        self.search_api = None\n",
        "        self.use_internet_search = False\n",
        "        self.article = None\n",
        "        self.metadata = {\n",
        "            \"title\": \"\",\n",
        "            \"keywords\": [],\n",
        "            \"word_count\": 0,\n",
        "            \"seo_score\": 0,\n",
        "            \"readability_score\": 0\n",
        "        }\n",
        "        self.configure_api()\n",
        "\n",
        "    def configure_api(self):\n",
        "        \"\"\"Configura a API do OpenAI.\"\"\"\n",
        "        if not self.openai_api_key:\n",
        "            # Verifica se estamos no Google Colab e tenta obter a chave do userdata\n",
        "            if IN_COLAB:\n",
        "                try:\n",
        "                    self.openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "                    print(\"‚úÖ Chave API OpenAI obtida com sucesso do armazenamento seguro do Colab.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è N√£o foi poss√≠vel obter a chave API do armazenamento seguro: {str(e)}\")\n",
        "                    print(\"Para configurar uma chave secreta no Google Colab:\")\n",
        "                    print(\"1. No menu lateral, clique em 'üîë' (Secrets)\")\n",
        "                    print(\"2. Adicione uma nova chave secreta com nome 'OPENAI_API_KEY' e seu valor\")\n",
        "                    self.openai_api_key = input(\"Digite sua chave de API OpenAI manualmente: \")\n",
        "            else:\n",
        "                self.openai_api_key = input(\"Digite sua chave de API OpenAI: \")\n",
        "\n",
        "        self.client = OpenAI(api_key=self.openai_api_key)\n",
        "\n",
        "        # Configura√ß√£o da API Serper se dispon√≠vel\n",
        "        if self.serper_api_key or self.use_internet_search:\n",
        "            self.search_api = SerperSearchAPI(api_key=self.serper_api_key)\n",
        "            self.use_internet_search = True\n",
        "\n",
        "    def enable_internet_search(self, serper_api_key=None):\n",
        "        \"\"\"\n",
        "        Habilita a busca na internet usando a API Serper.\n",
        "\n",
        "        Args:\n",
        "            serper_api_key (str, optional): Chave da API Serper.\n",
        "        \"\"\"\n",
        "        if serper_api_key:\n",
        "            self.serper_api_key = serper_api_key\n",
        "\n",
        "        self.search_api = SerperSearchAPI(api_key=self.serper_api_key)\n",
        "        self.use_internet_search = True\n",
        "        print(\"‚úÖ Busca na internet habilitada usando API Serper.\")\n",
        "\n",
        "    def search_for_topic(self, topic, keywords, num_results=5):\n",
        "        \"\"\"\n",
        "        Realiza uma busca na internet sobre o t√≥pico e palavras-chave.\n",
        "\n",
        "        Args:\n",
        "            topic (str): T√≥pico principal do artigo.\n",
        "            keywords (list): Lista de palavras-chave.\n",
        "            num_results (int): N√∫mero de resultados a retornar.\n",
        "\n",
        "        Returns:\n",
        "            str: Texto formatado com os resultados da busca.\n",
        "        \"\"\"\n",
        "        if not self.use_internet_search or not self.search_api:\n",
        "            return \"Busca na internet n√£o habilitada.\"\n",
        "\n",
        "        # Cria uma query de busca combinando o t√≥pico e palavras-chave\n",
        "        search_query = f\"{topic} {' '.join(keywords)}\"\n",
        "\n",
        "        # Realiza a busca\n",
        "        print(f\"üîç Buscando informa√ß√µes sobre: '{search_query}'\")\n",
        "        results = self.search_api.search(search_query, num_results)\n",
        "\n",
        "        # Extrai e formata os resultados\n",
        "        extracted_results = self.search_api.extract_search_results(results)\n",
        "        formatted_results = self.search_api.format_search_results_for_openai(extracted_results)\n",
        "\n",
        "        return formatted_results\n",
        "\n",
        "    def create_outline(self, topic, keywords, tone=\"informative\", use_search=True):\n",
        "        \"\"\"\n",
        "        Cria um esbo√ßo detalhado para o artigo.\n",
        "\n",
        "        Args:\n",
        "            topic (str): T√≥pico principal do artigo.\n",
        "            keywords (list): Lista de palavras-chave para SEO.\n",
        "            tone (str): Tom do artigo (informativo, persuasivo, etc).\n",
        "            use_search (bool): Se deve usar busca na internet para enriquecer o conte√∫do.\n",
        "\n",
        "        Returns:\n",
        "            dict: Estrutura do artigo com t√≠tulo e se√ß√µes.\n",
        "        \"\"\"\n",
        "        # Busca informa√ß√µes na internet se habilitado\n",
        "        search_results = \"\"\n",
        "        if use_search and self.use_internet_search:\n",
        "            search_results = self.search_for_topic(topic, keywords)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        Voc√™ √© um especialista em cria√ß√£o de conte√∫do para blogs otimizados para SEO.\n",
        "\n",
        "        Crie um esbo√ßo detalhado para um artigo de blog sobre \"{topic}\" com tom {tone}.\n",
        "\n",
        "        O artigo deve ter pelo menos 2000 palavras e incorporar as seguintes palavras-chave de forma natural:\n",
        "        {', '.join(keywords)}\n",
        "\n",
        "        O esbo√ßo deve incluir:\n",
        "        1. Um t√≠tulo atraente e otimizado para SEO (menos de 70 caracteres)\n",
        "        2. Uma meta-descri√ß√£o atraente (150-160 caracteres)\n",
        "        3. Uma introdu√ß√£o convincente\n",
        "        4. Pelo menos 5-7 se√ß√µes principais com subt√≠tulos descritivos e otimizados para SEO\n",
        "        5. Para cada se√ß√£o principal, liste 3-5 pontos-chave a serem abordados\n",
        "        6. Uma conclus√£o forte\n",
        "        7. Uma chamada para a√ß√£o eficaz\n",
        "\n",
        "        {search_results if search_results else \"\"}\n",
        "\n",
        "        Formate sua resposta como um JSON com a seguinte estrutura:\n",
        "        {{\n",
        "            \"title\": \"T√≠tulo do Artigo\",\n",
        "            \"meta_description\": \"Meta descri√ß√£o atrativa para SEO\",\n",
        "            \"sections\": [\n",
        "                {{\n",
        "                    \"heading\": \"Introdu√ß√£o\",\n",
        "                    \"points\": [\"ponto 1\", \"ponto 2\", \"ponto 3\"]\n",
        "                }},\n",
        "                {{\n",
        "                    \"heading\": \"Se√ß√£o 1\",\n",
        "                    \"points\": [\"ponto 1\", \"ponto 2\", \"ponto 3\"]\n",
        "                }},\n",
        "                ...\n",
        "            ]\n",
        "        }}\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            # Adiciona uma pausa de 1 segundo para evitar rate limiting\n",
        "            time.sleep(1)\n",
        "\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.7\n",
        "            )\n",
        "\n",
        "            outline_text = response.choices[0].message.content\n",
        "            # Extrair apenas o JSON da resposta\n",
        "            outline_json = re.search(r'({.*})', outline_text, re.DOTALL)\n",
        "            if outline_json:\n",
        "                try:\n",
        "                    outline = json.loads(outline_json.group(1))\n",
        "                except json.JSONDecodeError:\n",
        "                    # Tenta limpar o texto para torn√°-lo um JSON v√°lido\n",
        "                    cleaned_json = outline_json.group(1).replace(\"'\", '\"').replace(\"\\\\\", \"\\\\\\\\\")\n",
        "                    try:\n",
        "                        outline = json.loads(cleaned_json)\n",
        "                    except:\n",
        "                        print(f\"Erro ao processar a resposta como JSON. Resposta recebida:\\n{outline_text}\")\n",
        "                        return None\n",
        "            else:\n",
        "                try:\n",
        "                    outline = json.loads(outline_text)\n",
        "                except json.JSONDecodeError:\n",
        "                    # Se n√£o for poss√≠vel extrair o JSON, tenta criar um esbo√ßo manualmente\n",
        "                    print(f\"N√£o foi poss√≠vel extrair o JSON da resposta. Criando esbo√ßo manualmente.\")\n",
        "                    # Procura por um t√≠tulo\n",
        "                    title_match = re.search(r'[tT]√≠tulo:?\\s*(.+?)[\\n\\r]', outline_text)\n",
        "                    title = title_match.group(1) if title_match else \"Artigo sobre \" + topic\n",
        "\n",
        "                    # Cria se√ß√µes a partir de marcadores ou n√∫meros\n",
        "                    sections_text = re.split(r'[\\n\\r]+\\d+\\.|\\*\\*|##', outline_text)\n",
        "                    sections = []\n",
        "\n",
        "                    for section in sections_text:\n",
        "                        if len(section.strip()) > 10:  # Ignora se√ß√µes muito curtas\n",
        "                            parts = section.split('\\n', 1)\n",
        "                            heading = parts[0].strip().replace('*', '').replace('#', '')\n",
        "                            content = parts[1] if len(parts) > 1 else \"\"\n",
        "\n",
        "                            # Extrai pontos de marcadores\n",
        "                            points = re.findall(r'[\\n\\r]+[‚Ä¢\\-\\*]\\s*(.+?)[\\n\\r]', content)\n",
        "                            if not points:\n",
        "                                # Se n√£o encontrar marcadores, divide por frases\n",
        "                                sentences = re.findall(r'([^.!?]+[.!?])', content)\n",
        "                                points = sentences[:3] if sentences else [\"Detalhes sobre \" + heading]\n",
        "\n",
        "                            sections.append({\n",
        "                                \"heading\": heading,\n",
        "                                \"points\": points\n",
        "                            })\n",
        "\n",
        "                    outline = {\n",
        "                        \"title\": title,\n",
        "                        \"meta_description\": \"Artigo informativo sobre \" + topic,\n",
        "                        \"sections\": sections\n",
        "                    }\n",
        "\n",
        "            self.metadata[\"title\"] = outline[\"title\"]\n",
        "            self.metadata[\"keywords\"] = keywords\n",
        "\n",
        "            return outline\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao criar o esbo√ßo: {e}\")\n",
        "            return None\n",
        "\n",
        "    def generate_section(self, heading, points, keywords, previous_content=\"\", use_search=True):\n",
        "        \"\"\"\n",
        "        Gera o conte√∫do de uma se√ß√£o espec√≠fica do artigo.\n",
        "\n",
        "        Args:\n",
        "            heading (str): T√≠tulo da se√ß√£o.\n",
        "            points (list): Pontos chave a serem abordados na se√ß√£o.\n",
        "            keywords (list): Palavras-chave para SEO.\n",
        "            previous_content (str): Conte√∫do j√° gerado, para manter consist√™ncia.\n",
        "            use_search (bool): Se deve usar busca na internet para enriquecer o conte√∫do.\n",
        "\n",
        "        Returns:\n",
        "            str: Conte√∫do da se√ß√£o.\n",
        "        \"\"\"\n",
        "        # Busca informa√ß√µes na internet se habilitado\n",
        "        search_results = \"\"\n",
        "        if use_search and self.use_internet_search:\n",
        "            # Cria uma query de busca espec√≠fica para a se√ß√£o\n",
        "            search_query = f\"{heading} {' '.join(points[:2])} {' '.join(keywords[:2])}\"\n",
        "            results = self.search_api.search(search_query, 3)\n",
        "            extracted_results = self.search_api.extract_search_results(results)\n",
        "            search_results = self.search_api.format_search_results_for_openai(extracted_results)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        Voc√™ √© um redator especializado em conte√∫do para blogs otimizados para SEO.\n",
        "\n",
        "        Escreva uma se√ß√£o detalhada para um artigo de blog com o t√≠tulo \"{heading}\".\n",
        "\n",
        "        Aborde os seguintes pontos de forma abrangente e envolvente:\n",
        "        {', '.join(points)}\n",
        "\n",
        "        Incorpore naturalmente as seguintes palavras-chave quando for apropriado:\n",
        "        {', '.join(keywords)}\n",
        "\n",
        "        {search_results if search_results else \"\"}\n",
        "\n",
        "        Algumas orienta√ß√µes:\n",
        "        - Escreva em portugu√™s brasileiro formal, mas conversacional\n",
        "        - Use par√°grafos curtos (3-4 frases)\n",
        "        - Use subt√≠tulos H3 quando necess√°rio para dividir se√ß√µes longas\n",
        "        - Inclua exemplos concretos e espec√≠ficos\n",
        "        - Use linguagem ativa e envolvente\n",
        "        - Evite jarg√µes desnecess√°rios\n",
        "        - Certifique-se de que o conte√∫do flua naturalmente e seja f√°cil de ler\n",
        "        - No m√≠nimo 300-400 palavras para esta se√ß√£o\n",
        "\n",
        "        {f\"Mantenha consist√™ncia com o conte√∫do anterior: {previous_content[:300]}...\" if previous_content else \"\"}\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            # Adiciona uma pausa de 1 segundo para evitar rate limiting\n",
        "            time.sleep(1)\n",
        "\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.7\n",
        "            )\n",
        "\n",
        "            section_content = response.choices[0].message.content\n",
        "            return section_content\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao gerar a se√ß√£o '{heading}': {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def generate_full_article(self, outline, use_search=True):\n",
        "        \"\"\"\n",
        "        Gera o artigo completo baseado no esbo√ßo.\n",
        "\n",
        "        Args:\n",
        "            outline (dict): Esbo√ßo estruturado do artigo.\n",
        "            use_search (bool): Se deve usar busca na internet para enriquecer o conte√∫do.\n",
        "\n",
        "        Returns:\n",
        "            str: Artigo completo formatado.\n",
        "        \"\"\"\n",
        "        full_article = f\"# {outline['title']}\\n\\n\"\n",
        "        previous_content = \"\"\n",
        "\n",
        "        print(\"Gerando artigo completo...\")\n",
        "        for section in tqdm(outline['sections']):\n",
        "            heading = section['heading']\n",
        "            points = section['points']\n",
        "\n",
        "            # Determina o n√≠vel de cabe√ßalho (Introdu√ß√£o e Conclus√£o s√£o H2, o resto H2 tamb√©m)\n",
        "            header_level = \"##\"\n",
        "\n",
        "            section_content = self.generate_section(\n",
        "                heading,\n",
        "                points,\n",
        "                self.metadata[\"keywords\"],\n",
        "                previous_content,\n",
        "                use_search\n",
        "            )\n",
        "\n",
        "            full_article += f\"{header_level} {heading}\\n\\n{section_content}\\n\\n\"\n",
        "            previous_content += section_content\n",
        "\n",
        "        self.article = full_article\n",
        "        self.count_words()\n",
        "\n",
        "        # Verifica se o tamanho m√≠nimo foi atingido\n",
        "        if self.metadata[\"word_count\"] < self.min_word_count:\n",
        "            print(f\"O artigo tem apenas {self.metadata['word_count']} palavras. Expandindo para atingir o m√≠nimo de {self.min_word_count}...\")\n",
        "            self.expand_article(use_search)\n",
        "\n",
        "        return self.article\n",
        "\n",
        "    def expand_article(self, use_search=True):\n",
        "        \"\"\"\n",
        "        Expande o artigo para atingir o n√∫mero m√≠nimo de palavras.\n",
        "\n",
        "        Args:\n",
        "            use_search (bool): Se deve usar busca na internet para enriquecer o conte√∫do.\n",
        "        \"\"\"\n",
        "        words_needed = self.min_word_count - self.metadata[\"word_count\"]\n",
        "        sections = self.article.split(\"##\")\n",
        "\n",
        "        # Identifica as se√ß√µes mais curtas para expandir\n",
        "        section_lengths = [(i, len(section.split())) for i, section in enumerate(sections[1:])]\n",
        "        section_lengths.sort(key=lambda x: x[1])\n",
        "\n",
        "        # Expande as se√ß√µes mais curtas\n",
        "        for idx, _ in section_lengths[:3]:\n",
        "            if words_needed <= 0:\n",
        "                break\n",
        "\n",
        "            # Extrai t√≠tulo e conte√∫do da se√ß√£o\n",
        "            section = sections[idx + 1]\n",
        "            section_parts = section.split(\"\\n\\n\", 1)\n",
        "            if len(section_parts) < 2:\n",
        "                continue\n",
        "\n",
        "            heading = section_parts[0].strip()\n",
        "            content = section_parts[1]\n",
        "\n",
        "            # Busca informa√ß√µes adicionais na internet se habilitado\n",
        "            search_results = \"\"\n",
        "            if use_search and self.use_internet_search:\n",
        "                search_query = f\"{heading} detalhado {' '.join(self.metadata['keywords'][:2])}\"\n",
        "                results = self.search_api.search(search_query, 3)\n",
        "                extracted_results = self.search_api.extract_search_results(results)\n",
        "                search_results = self.search_api.format_search_results_for_openai(extracted_results)\n",
        "\n",
        "            # Gera conte√∫do adicional\n",
        "            prompt = f\"\"\"\n",
        "            Expanda o seguinte conte√∫do de blog para adicionar mais detalhes, exemplos e informa√ß√µes √∫teis.\n",
        "            Adicione pelo menos 300 palavras de conte√∫do relevante, mantendo o estilo e tom do texto original.\n",
        "            Incorpore naturalmente as palavras-chave: {', '.join(self.metadata[\"keywords\"])}\n",
        "\n",
        "            {search_results if search_results else \"\"}\n",
        "\n",
        "            Se√ß√£o: {heading}\n",
        "\n",
        "            Conte√∫do atual:\n",
        "            {content}\n",
        "            \"\"\"\n",
        "\n",
        "            try:\n",
        "                # Adiciona uma pausa de 1 segundo para evitar rate limiting\n",
        "                time.sleep(1)\n",
        "\n",
        "                response = self.client.chat.completions.create(\n",
        "                    model=self.model,\n",
        "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                    temperature=0.7\n",
        "                )\n",
        "\n",
        "                expanded_content = response.choices[0].message.content\n",
        "                sections[idx + 1] = f\"{heading}\\n\\n{expanded_content}\"\n",
        "                words_needed -= 300  # Estimativa de palavras adicionadas\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao expandir a se√ß√£o: {e}\")\n",
        "\n",
        "        # Re√∫ne o artigo expandido\n",
        "        self.article = sections[0] + \"##\".join(sections[1:])\n",
        "        self.count_words()\n",
        "\n",
        "    def count_words(self):\n",
        "        \"\"\"Conta o n√∫mero de palavras no artigo.\"\"\"\n",
        "        if self.article:\n",
        "            # Usa um m√©todo mais simples para contar palavras, evitando erros de tokeniza√ß√£o\n",
        "            try:\n",
        "                words = word_tokenize(self.article, language='portuguese')\n",
        "            except LookupError:\n",
        "                # M√©todo alternativo de contagem de palavras\n",
        "                words = self.article.split()\n",
        "\n",
        "            # Remove pontua√ß√£o e outros caracteres n√£o-palavras\n",
        "            words = [word for word in words if re.match(r'\\w+', word)]\n",
        "            self.metadata[\"word_count\"] = len(words)\n",
        "\n",
        "    def calculate_seo_score(self):\n",
        "        \"\"\"\n",
        "        Calcula uma pontua√ß√£o de SEO para o artigo.\n",
        "\n",
        "        Returns:\n",
        "            float: Pontua√ß√£o de SEO entre 0 e 100.\n",
        "        \"\"\"\n",
        "        if not self.article:\n",
        "            return 0\n",
        "\n",
        "        score = 0\n",
        "        text_lower = self.article.lower()\n",
        "\n",
        "        # Verifica o uso de palavras-chave\n",
        "        for keyword in self.metadata[\"keywords\"]:\n",
        "            keyword_lower = keyword.lower()\n",
        "            count = text_lower.count(keyword_lower)\n",
        "\n",
        "            # Densidade de palavras-chave ideal (0.5% - 2%)\n",
        "            density = count / self.metadata[\"word_count\"] * 100\n",
        "            if 0.5 <= density <= 2.0:\n",
        "                score += 20 / len(self.metadata[\"keywords\"])\n",
        "            elif density > 0:\n",
        "                score += 10 / len(self.metadata[\"keywords\"])\n",
        "\n",
        "        # Verifica presen√ßa de palavras-chave em t√≠tulos\n",
        "        title_score = 0\n",
        "        title_lines = re.findall(r'#{1,3}\\s+(.+)', self.article)\n",
        "        for title in title_lines:\n",
        "            title_lower = title.lower()\n",
        "            for keyword in self.metadata[\"keywords\"]:\n",
        "                if keyword.lower() in title_lower:\n",
        "                    title_score += 1\n",
        "\n",
        "        # Normaliza a pontua√ß√£o de t√≠tulos (max 20 pontos)\n",
        "        title_score = min(title_score, 20)\n",
        "        score += title_score\n",
        "\n",
        "        # Verifica tamanho do artigo\n",
        "        if self.metadata[\"word_count\"] >= self.min_word_count:\n",
        "            score += 20\n",
        "        elif self.metadata[\"word_count\"] >= self.min_word_count * 0.8:\n",
        "            score += 10\n",
        "\n",
        "        # Verifica estrutura do artigo (presen√ßa de H2, H3)\n",
        "        if len(re.findall(r'##\\s+', self.article)) >= 4:\n",
        "            score += 20\n",
        "        else:\n",
        "            h2_count = len(re.findall(r'##\\s+', self.article))\n",
        "            score += h2_count * 5\n",
        "\n",
        "        # Verifica presen√ßa de links (n√£o implementado aqui, precisaria de mais contexto)\n",
        "        # Para uma implementa√ß√£o completa, voc√™ poderia adicionar verifica√ß√£o de links\n",
        "\n",
        "        # Verifica comprimento dos par√°grafos (ideal: 3-4 frases)\n",
        "        paragraphs = re.findall(r'\\n\\n(.+?)\\n\\n', self.article, re.DOTALL)\n",
        "        short_paragraphs = 0\n",
        "        for para in paragraphs:\n",
        "            sentences = re.findall(r'[.!?]+', para)\n",
        "            if 1 <= len(sentences) <= 4:\n",
        "                short_paragraphs += 1\n",
        "\n",
        "        if len(paragraphs) > 0:\n",
        "            paragraph_score = short_paragraphs / len(paragraphs) * 20\n",
        "            score += paragraph_score\n",
        "\n",
        "        self.metadata[\"seo_score\"] = round(score, 2)\n",
        "        return self.metadata[\"seo_score\"]\n",
        "\n",
        "    def calculate_readability_score(self):\n",
        "        \"\"\"\n",
        "        Calcula uma pontua√ß√£o de legibilidade para o artigo.\n",
        "\n",
        "        Returns:\n",
        "            float: Pontua√ß√£o de legibilidade entre 0 e 100.\n",
        "        \"\"\"\n",
        "        if not self.article:\n",
        "            return 0\n",
        "\n",
        "        # Tokeniza o texto de maneira segura\n",
        "        try:\n",
        "            tokens = word_tokenize(self.article, language='portuguese')\n",
        "        except LookupError:\n",
        "            # M√©todo alternativo de tokeniza√ß√£o\n",
        "            tokens = [word for word in self.article.split() if re.match(r'\\w+', word)]\n",
        "\n",
        "        if not tokens:\n",
        "            return 0\n",
        "\n",
        "        # Calcula o comprimento m√©dio das palavras\n",
        "        avg_word_length = sum(len(word) for word in tokens) / len(tokens)\n",
        "\n",
        "        # Estima o n√∫mero de frases usando regex\n",
        "        sentences = re.findall(r'[^.!?]+[.!?]', self.article)\n",
        "        num_sentences = len(sentences) if sentences else 1\n",
        "\n",
        "        # Calcula palavras por frase (m√©dia)\n",
        "        words_per_sentence = self.metadata[\"word_count\"] / max(num_sentences, 1)\n",
        "\n",
        "        # Pontua√ß√£o baseada em simplicidade de palavras (quanto menor o comprimento m√©dio, melhor, at√© certo ponto)\n",
        "        word_length_score = 50 - (abs(avg_word_length - 5) * 10)\n",
        "        word_length_score = max(0, min(50, word_length_score))\n",
        "\n",
        "        # Pontua√ß√£o baseada no comprimento das frases (ideal: 15-20 palavras por frase)\n",
        "        sentence_length_score = 50 - (abs(words_per_sentence - 17.5) * 2)\n",
        "        sentence_length_score = max(0, min(50, sentence_length_score))\n",
        "\n",
        "        readability_score = word_length_score + sentence_length_score\n",
        "        self.metadata[\"readability_score\"] = round(readability_score, 2)\n",
        "\n",
        "        # Para refer√™ncias nas sugest√µes de melhoria\n",
        "        self.avg_word_length = avg_word_length\n",
        "        self.words_per_sentence = words_per_sentence\n",
        "\n",
        "        return self.metadata[\"readability_score\"]\n",
        "\n",
        "    def analyze_article(self):\n",
        "        \"\"\"\n",
        "        Analisa o artigo e retorna m√©tricas.\n",
        "\n",
        "        Returns:\n",
        "            dict: Metadados e pontua√ß√µes do artigo.\n",
        "        \"\"\"\n",
        "        if not self.article:\n",
        "            return {\"error\": \"Nenhum artigo gerado ainda.\"}\n",
        "\n",
        "        self.count_words()\n",
        "        seo_score = self.calculate_seo_score()\n",
        "        readability_score = self.calculate_readability_score()\n",
        "\n",
        "        # An√°lise de densidade de palavras-chave\n",
        "        keyword_density = {}\n",
        "        text_lower = self.article.lower()\n",
        "        for keyword in self.metadata[\"keywords\"]:\n",
        "            keyword_lower = keyword.lower()\n",
        "            count = text_lower.count(keyword_lower)\n",
        "            density = count / self.metadata[\"word_count\"] * 100\n",
        "            keyword_density[keyword] = {\n",
        "                \"count\": count,\n",
        "                \"density\": round(density, 2)\n",
        "            }\n",
        "\n",
        "        # Prepara sugest√µes de melhoria\n",
        "        suggestions = []\n",
        "        if seo_score < 70:\n",
        "            if len(re.findall(r'##\\s+', self.article)) < 4:\n",
        "                suggestions.append(\"Adicione mais se√ß√µes com subt√≠tulos H2 para melhorar a estrutura do artigo.\")\n",
        "\n",
        "            low_density_keywords = [k for k, v in keyword_density.items() if v[\"density\"] < 0.5]\n",
        "            if low_density_keywords:\n",
        "                suggestions.append(f\"Aumente a frequ√™ncia das seguintes palavras-chave: {', '.join(low_density_keywords)}\")\n",
        "\n",
        "            high_density_keywords = [k for k, v in keyword_density.items() if v[\"density\"] > 2.0]\n",
        "            if high_density_keywords:\n",
        "                suggestions.append(f\"Reduza a frequ√™ncia das seguintes palavras-chave (poss√≠vel keyword stuffing): {', '.join(high_density_keywords)}\")\n",
        "\n",
        "        if readability_score < 70:\n",
        "            if self.avg_word_length > 6:\n",
        "                suggestions.append(\"Use palavras mais simples e curtas para melhorar a legibilidade.\")\n",
        "            if self.words_per_sentence > 20:\n",
        "                suggestions.append(\"Reduza o comprimento das frases para melhorar a legibilidade.\")\n",
        "\n",
        "        return {\n",
        "            \"title\": self.metadata[\"title\"],\n",
        "            \"word_count\": self.metadata[\"word_count\"],\n",
        "            \"seo_score\": self.metadata[\"seo_score\"],\n",
        "            \"readability_score\": self.metadata[\"readability_score\"],\n",
        "            \"keyword_density\": keyword_density,\n",
        "            \"improvement_suggestions\": suggestions\n",
        "        }\n",
        "\n",
        "    def save_article(self, format=\"markdown\"):\n",
        "        \"\"\"\n",
        "        Salva o artigo no formato especificado.\n",
        "\n",
        "        Args:\n",
        "            format (str): Formato de sa√≠da ('markdown', 'html', 'text')\n",
        "\n",
        "        Returns:\n",
        "            str: Caminho do arquivo salvo.\n",
        "        \"\"\"\n",
        "        if not self.article:\n",
        "            return {\"error\": \"Nenhum artigo gerado ainda.\"}\n",
        "\n",
        "        filename = re.sub(r'[^\\w\\s]', '', self.metadata[\"title\"])\n",
        "        filename = re.sub(r'\\s+', '_', filename.lower())\n",
        "\n",
        "        if format == \"markdown\":\n",
        "            filename = f\"{filename}.md\"\n",
        "            with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(self.article)\n",
        "\n",
        "        elif format == \"html\":\n",
        "            filename = f\"{filename}.html\"\n",
        "\n",
        "            # Convers√£o b√°sica de Markdown para HTML\n",
        "            html = self.article\n",
        "            html = re.sub(r'# (.*?)\\n', r'<h1>\\1</h1>\\n', html)\n",
        "            html = re.sub(r'## (.*?)\\n', r'<h2>\\1</h2>\\n', html)\n",
        "            html = re.sub(r'### (.*?)\\n', r'<h3>\\1</h3>\\n', html)\n",
        "            html = re.sub(r'\\n\\n(.*?)\\n\\n', r'<p>\\1</p>\\n', html)\n",
        "\n",
        "            with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(f\"\"\"<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>{self.metadata[\"title\"]}</title>\n",
        "    <style>\n",
        "        body {{ font-family: Arial, sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; padding: 20px; }}\n",
        "        h1 {{ color: #333; }}\n",
        "        h2 {{ color: #444; margin-top: 30px; }}\n",
        "        h3 {{ color: #555; }}\n",
        "        p {{ margin-bottom: 20px; }}\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "{html}\n",
        "</body>\n",
        "</html>\"\"\")\n",
        "\n",
        "        elif format == \"text\":\n",
        "            filename = f\"{filename}.txt\"\n",
        "            # Remove marcadores de Markdown\n",
        "            text = re.sub(r'#+ ', '', self.article)\n",
        "            with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(text)\n",
        "\n",
        "        # Para uso no Google Colab, permitir download do arquivo\n",
        "        if IN_COLAB:\n",
        "            try:\n",
        "                from google.colab import files\n",
        "                files.download(filename)\n",
        "                return {\"message\": f\"Arquivo '{filename}' criado e dispon√≠vel para download.\"}\n",
        "            except Exception as e:\n",
        "                return {\"message\": f\"Arquivo '{filename}' criado, mas ocorreu um erro ao tentar o download: {str(e)}\"}\n",
        "        else:\n",
        "            return {\"message\": f\"Arquivo '{filename}' criado com sucesso.\"}\n",
        "\n",
        "# Adiciona c√≥digo para configurar as chaves API no Colab (adicione no in√≠cio do notebook)\n",
        "def setup_api_keys():\n",
        "    \"\"\"Configura as chaves API da OpenAI e Serper no Google Colab usando userdata.\"\"\"\n",
        "    if not IN_COLAB:\n",
        "        print(\"Esta fun√ß√£o s√≥ funciona no ambiente Google Colab.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n===== üîë CONFIGURA√á√ÉO DAS CHAVES API =====\\n\")\n",
        "\n",
        "    # Configura√ß√£o da chave OpenAI\n",
        "    print(\"=== Configura√ß√£o da chave OpenAI ===\")\n",
        "    print(\"Esta fun√ß√£o ir√° configurar sua chave API da OpenAI de forma segura no Google Colab.\")\n",
        "    print(\"Sua chave ser√° armazenada nas vari√°veis secretas (Secrets) e n√£o ficar√° vis√≠vel no notebook.\")\n",
        "\n",
        "    # Verifica se j√° existe uma chave configurada\n",
        "    try:\n",
        "        existing_key = userdata.get('OPENAI_API_KEY')\n",
        "        if existing_key:\n",
        "            print(\"‚úÖ J√° existe uma chave API OpenAI configurada.\")\n",
        "            replace = input(\"Deseja substituir a chave existente? (s/n): \").lower()\n",
        "            if replace != 's':\n",
        "                print(\"Mantendo a chave existente.\")\n",
        "            else:\n",
        "                setup_openai_key()\n",
        "        else:\n",
        "            setup_openai_key()\n",
        "    except:\n",
        "        setup_openai_key()\n",
        "\n",
        "    # Configura√ß√£o da chave Serper\n",
        "    print(\"\\n=== Configura√ß√£o da chave Serper para busca na web ===\")\n",
        "    print(\"Esta fun√ß√£o ir√° configurar sua chave API Serper de forma segura no Google Colab.\")\n",
        "    print(\"Sua chave ser√° armazenada nas vari√°veis secretas (Secrets) e n√£o ficar√° vis√≠vel no notebook.\")\n",
        "\n",
        "    use_serper = input(\"Deseja configurar uma chave API Serper para busca na web? (s/n): \").lower()\n",
        "    if use_serper == 's':\n",
        "        # Verifica se j√° existe uma chave configurada\n",
        "        try:\n",
        "            existing_key = userdata.get('SERPER_API_KEY')\n",
        "            if existing_key:\n",
        "                print(\"‚úÖ J√° existe uma chave API Serper configurada.\")\n",
        "                replace = input(\"Deseja substituir a chave existente? (s/n): \").lower()\n",
        "                if replace != 's':\n",
        "                    print(\"Mantendo a chave existente.\")\n",
        "                else:\n",
        "                    setup_serper_key()\n",
        "            else:\n",
        "                setup_serper_key()\n",
        "        except:\n",
        "            setup_serper_key()\n",
        "\n",
        "    print(\"\\nConfigura√ß√µes conclu√≠das.\")\n",
        "    print(\"Agora voc√™ pode executar o gerador de artigos de blog com as chaves armazenadas de forma segura.\")\n",
        "\n",
        "def setup_openai_key():\n",
        "    \"\"\"Configura a chave API da OpenAI.\"\"\"\n",
        "    new_key = input(\"\\nDigite sua chave API da OpenAI (come√ßando com 'sk-'): \")\n",
        "\n",
        "    if not new_key.startswith('sk-'):\n",
        "        print(\"‚ö†Ô∏è Aviso: A chave n√£o come√ßa com 'sk-', o que √© o padr√£o para chaves OpenAI.\")\n",
        "        confirm = input(\"Tem certeza de que esta √© uma chave v√°lida? (s/n): \").lower()\n",
        "        if confirm != 's':\n",
        "            print(\"Opera√ß√£o cancelada.\")\n",
        "            return\n",
        "\n",
        "    print(\"\\nPara salvar a chave no Google Colab:\")\n",
        "    print(\"1. No menu lateral, clique em 'üîë' (Secrets)\")\n",
        "    print(\"2. Adicione uma nova chave secreta com:\")\n",
        "    print(\"   - Nome: OPENAI_API_KEY\")\n",
        "    print(f\"   - Valor: {new_key}\")\n",
        "    print(\"3. Clique em 'Adicionar'\")\n",
        "\n",
        "    # Testa a chave (opcional)\n",
        "    test = input(\"\\nDeseja testar a chave agora? (s/n): \").lower()\n",
        "    if test == 's':\n",
        "        try:\n",
        "            client = OpenAI(api_key=new_key)\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[{\"role\": \"user\", \"content\": \"Responda apenas com 'OK' se voc√™ pode me ver.\"}],\n",
        "                max_tokens=10\n",
        "            )\n",
        "            result = response.choices[0].message.content\n",
        "            if \"ok\" in result.lower():\n",
        "                print(\"‚úÖ Teste bem-sucedido! A chave API est√° funcionando.\")\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è A API respondeu com: {result}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao testar a chave: {str(e)}\")\n",
        "\n",
        "def setup_serper_key():\n",
        "    \"\"\"Configura a chave API da Serper.\"\"\"\n",
        "    new_key = input(\"\\nDigite sua chave API da Serper: \")\n",
        "\n",
        "    print(\"\\nPara salvar a chave no Google Colab:\")\n",
        "    print(\"1. No menu lateral, clique em 'üîë' (Secrets)\")\n",
        "    print(\"2. Adicione uma nova chave secreta com:\")\n",
        "    print(\"   - Nome: SERPER_API_KEY\")\n",
        "    print(f\"   - Valor: {new_key}\")\n",
        "    print(\"3. Clique em 'Adicionar'\")\n",
        "\n",
        "    # Testa a chave (opcional)\n",
        "    test = input(\"\\nDeseja testar a chave agora? (s/n): \").lower()\n",
        "    if test == 's':\n",
        "        try:\n",
        "            headers = {\n",
        "                \"X-API-KEY\": new_key,\n",
        "                \"Content-Type\": \"application/json\"\n",
        "            }\n",
        "            payload = {\n",
        "                \"q\": \"teste serper api\",\n",
        "                \"num\": 1\n",
        "            }\n",
        "            response = requests.post(\n",
        "                \"https://google.serper.dev/search\",\n",
        "                headers=headers,\n",
        "                json=payload\n",
        "            )\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                print(\"‚úÖ Teste bem-sucedido! A chave API Serper est√° funcionando.\")\n",
        "            else:\n",
        "                print(f\"‚ùå Erro: {response.status_code}\")\n",
        "                print(response.text)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao testar a chave: {str(e)}\")\n",
        "\n",
        "# Interface principal para uso no Google Colab\n",
        "def run_blog_article_generator():\n",
        "    \"\"\"Interface principal para o gerador de artigos de blog.\"\"\"\n",
        "    print(\"\\n===== üìù GERADOR DE ARTIGOS DE BLOG OTIMIZADOS PARA SEO =====\\n\")\n",
        "\n",
        "    # Obt√©m a chave API da OpenAI\n",
        "    openai_api_key = None\n",
        "    if IN_COLAB:\n",
        "        try:\n",
        "            openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "            print(\"‚úÖ Chave API OpenAI obtida com sucesso do armazenamento seguro do Colab.\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è N√£o foi poss√≠vel obter a chave API do armazenamento seguro: {str(e)}\")\n",
        "            print(\"\\nPara configurar uma chave secreta no Google Colab:\")\n",
        "            print(\"1. No menu lateral, clique em 'üîë' (Secrets)\")\n",
        "            print(\"2. Adicione uma nova chave secreta com nome 'OPENAI_API_KEY' e seu valor\")\n",
        "            openai_api_key = input(\"\\nDigite sua chave de API OpenAI: \")\n",
        "    else:\n",
        "        openai_api_key = input(\"Digite sua chave de API OpenAI: \")\n",
        "\n",
        "    # Verifica se deseja usar a busca na internet\n",
        "    use_internet_search = input(\"\\nDeseja usar a busca na internet para enriquecer o conte√∫do? (s/n): \").lower() == 's'\n",
        "\n",
        "    serper_api_key = None\n",
        "    if use_internet_search:\n",
        "        if IN_COLAB:\n",
        "            try:\n",
        "                serper_api_key = userdata.get('SERPER_API_KEY')\n",
        "                print(\"‚úÖ Chave API Serper obtida com sucesso do armazenamento seguro do Colab.\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è N√£o foi poss√≠vel obter a chave API Serper do armazenamento seguro: {str(e)}\")\n",
        "                print(\"\\nPara configurar uma chave secreta no Google Colab:\")\n",
        "                print(\"1. No menu lateral, clique em 'üîë' (Secrets)\")\n",
        "                print(\"2. Adicione uma nova chave secreta com nome 'SERPER_API_KEY' e seu valor\")\n",
        "                serper_api_key = input(\"\\nDigite sua chave de API Serper: \")\n",
        "        else:\n",
        "            serper_api_key = input(\"Digite sua chave de API Serper: \")\n",
        "\n",
        "    # Seleciona o modelo\n",
        "    print(\"\\nSelecione o modelo da OpenAI:\")\n",
        "    print(\"\\nReasoning models:\")\n",
        "    print(\"1. o3-mini - Fast, flexible, intelligent reasoning model\")\n",
        "    print(\"2. o1 - High-intelligence reasoning model\")\n",
        "    print(\"3. o1-mini - A faster, more affordable reasoning model than o1\")\n",
        "    print(\"4. o1-pro - A version of o1 with more compute for better responses\")\n",
        "\n",
        "    print(\"\\nFlagship chat models:\")\n",
        "    print(\"5. GPT-4.5 Preview - Largest and most capable GPT model\")\n",
        "    print(\"6. GPT-4o - Fast, intelligent, flexible GPT model\")\n",
        "    print(\"7. ChatGPT-4o - GPT-4o model used in ChatGPT\")\n",
        "\n",
        "    print(\"\\nCost-optimized models:\")\n",
        "    print(\"8. GPT-4o mini - Fast, affordable small model for focused tasks\")\n",
        "\n",
        "    print(\"\\nOlder GPT models:\")\n",
        "    print(\"9. GPT-4 Turbo - An older high-intelligence GPT model\")\n",
        "    print(\"10. GPT-4 - An older high-intelligence GPT model\")\n",
        "    print(\"11. GPT-3.5 Turbo - Legacy GPT model for cheaper chat and non-chat tasks\")\n",
        "\n",
        "    model_choice = input(\"\\nEscolha o n√∫mero correspondente (padr√£o: 11): \") or \"11\"\n",
        "\n",
        "    models = {\n",
        "        \"1\": \"o3-mini\",\n",
        "        \"2\": \"o1\",\n",
        "        \"3\": \"o1-mini\",\n",
        "        \"4\": \"o1-pro\",\n",
        "        \"5\": \"gpt-4.5-preview\",\n",
        "        \"6\": \"gpt-4o\",\n",
        "        \"7\": \"gpt-4o\",  # ChatGPT-4o usa o mesmo modelo que GPT-4o\n",
        "        \"8\": \"gpt-4o-mini\",\n",
        "        \"9\": \"gpt-4-turbo\",\n",
        "        \"10\": \"gpt-4\",\n",
        "        \"11\": \"gpt-3.5-turbo\"\n",
        "    }\n",
        "\n",
        "    selected_model = models.get(model_choice, \"gpt-3.5-turbo\")\n",
        "    print(f\"Modelo selecionado: {selected_model}\")\n",
        "\n",
        "    # Inicializa o gerador\n",
        "    generator = BlogArticleGenerator(\n",
        "        openai_api_key=openai_api_key,\n",
        "        serper_api_key=serper_api_key,\n",
        "        model=selected_model\n",
        "    )\n",
        "\n",
        "    if use_internet_search:\n",
        "        generator.enable_internet_search(serper_api_key)\n",
        "\n",
        "    # Solicita informa√ß√µes b√°sicas\n",
        "    topic = input(\"\\nQual √© o t√≥pico principal do artigo? \")\n",
        "\n",
        "    print(\"\\nInsira as palavras-chave para SEO (separadas por v√≠rgula): \")\n",
        "    keywords_input = input()\n",
        "    keywords = [k.strip() for k in keywords_input.split(\",\")]\n",
        "\n",
        "    tone_options = [\"informativo\", \"persuasivo\", \"conversacional\", \"t√©cnico\", \"inspirador\"]\n",
        "    print(\"\\nSelecione o tom do artigo:\")\n",
        "    for i, tone in enumerate(tone_options):\n",
        "        print(f\"{i+1}. {tone}\")\n",
        "\n",
        "    tone_idx = int(input(\"Escolha o n√∫mero correspondente: \")) - 1\n",
        "    tone = tone_options[tone_idx]\n",
        "\n",
        "    # Cria o esbo√ßo\n",
        "    print(\"\\nCriando esbo√ßo do artigo...\")\n",
        "\n",
        "    # Tenta at√© 3 vezes com diferentes modelos se falhar\n",
        "    attempts = 0\n",
        "    outline = None\n",
        "    available_models = [\"gpt-3.5-turbo\", \"gpt-4o-mini\", \"gpt-4o\"]\n",
        "\n",
        "    while attempts < 3 and outline is None:\n",
        "        try:\n",
        "            outline = generator.create_outline(topic, keywords, tone, use_search=use_internet_search)\n",
        "            if outline:\n",
        "                break\n",
        "        except Exception as e:\n",
        "            print(f\"Tentativa {attempts+1} falhou: {str(e)}\")\n",
        "\n",
        "        attempts += 1\n",
        "        if attempts < 3:\n",
        "            # Tenta com um modelo diferente\n",
        "            fallback_model = available_models[attempts % len(available_models)]\n",
        "            print(f\"Tentando novamente com o modelo {fallback_model}...\")\n",
        "            generator.model = fallback_model\n",
        "\n",
        "    if not outline:\n",
        "        print(\"‚ùå Erro ao criar o esbo√ßo ap√≥s v√°rias tentativas. Verifique sua chave de API e tente novamente.\")\n",
        "        return\n",
        "\n",
        "    # Mostra o esbo√ßo\n",
        "    print(\"\\n===== ESBO√áO DO ARTIGO =====\")\n",
        "    print(f\"üìå T√≠tulo: {outline['title']}\")\n",
        "    print(f\"üìù Meta Descri√ß√£o: {outline.get('meta_description', 'N√£o dispon√≠vel')}\")\n",
        "    print(\"\\nüìë Se√ß√µes:\")\n",
        "    for i, section in enumerate(outline['sections']):\n",
        "        print(f\"  {i+1}. {section['heading']}\")\n",
        "        for point in section['points']:\n",
        "            print(f\"     ‚Ä¢ {point}\")\n",
        "\n",
        "    # Pergunta se deseja prosseguir\n",
        "    proceed = input(\"\\nDeseja gerar o artigo completo com base neste esbo√ßo? (s/n): \")\n",
        "    if proceed.lower() != 's':\n",
        "        print(\"Opera√ß√£o cancelada.\")\n",
        "        return\n",
        "\n",
        "    # Gera o artigo\n",
        "    article = generator.generate_full_article(outline, use_search=use_internet_search)\n",
        "\n",
        "    # Mostra estat√≠sticas\n",
        "    analysis = generator.analyze_article()\n",
        "\n",
        "    print(\"\\n===== AN√ÅLISE DO ARTIGO =====\")\n",
        "    print(f\"üìä Contagem de palavras: {analysis['word_count']} (m√≠nimo: {generator.min_word_count})\")\n",
        "    print(f\"üîç Pontua√ß√£o SEO: {analysis['seo_score']}/100\")\n",
        "    print(f\"üìñ Pontua√ß√£o de legibilidade: {analysis['readability_score']}/100\")\n",
        "\n",
        "    print(\"\\nüìà Densidade de palavras-chave:\")\n",
        "    for keyword, data in analysis['keyword_density'].items():\n",
        "        status = \"‚úÖ\" if 0.5 <= data['density'] <= 2.0 else \"‚ö†Ô∏è\"\n",
        "        print(f\"  {status} '{keyword}': {data['count']} ocorr√™ncias ({data['density']}%)\")\n",
        "\n",
        "    if analysis['improvement_suggestions']:\n",
        "        print(\"\\nüõ†Ô∏è Sugest√µes de melhoria:\")\n",
        "        for suggestion in analysis['improvement_suggestions']:\n",
        "            print(f\"  ‚Ä¢ {suggestion}\")\n",
        "\n",
        "    # Exibe uma pr√©via do artigo\n",
        "    print(\"\\n===== PR√âVIA DO ARTIGO =====\")\n",
        "    preview_lines = article.split(\"\\n\")[:20]\n",
        "    preview = \"\\n\".join(preview_lines)\n",
        "    print(f\"{preview}\\n...\\n\")\n",
        "\n",
        "    # Op√ß√µes de salvar\n",
        "    print(\"Deseja salvar o artigo? Escolha o formato:\")\n",
        "    print(\"1. Markdown (.md)\")\n",
        "    print(\"2. HTML (.html)\")\n",
        "    print(\"3. Texto (.txt)\")\n",
        "    print(\"4. Mostrar artigo completo na tela\")\n",
        "    print(\"5. N√£o salvar\")\n",
        "\n",
        "    save_option = int(input(\"Escolha o n√∫mero correspondente: \"))\n",
        "\n",
        "    if save_option == 1:\n",
        "        result = generator.save_article(\"markdown\")\n",
        "        print(result[\"message\"])\n",
        "    elif save_option == 2:\n",
        "        result = generator.save_article(\"html\")\n",
        "        print(result[\"message\"])\n",
        "    elif save_option == 3:\n",
        "        result = generator.save_article(\"text\")\n",
        "        print(result[\"message\"])\n",
        "    elif save_option == 4:\n",
        "        display(Markdown(article))\n",
        "    else:\n",
        "        print(\"Artigo n√£o salvo.\")\n",
        "\n",
        "    print(\"\\n‚úÖ Opera√ß√£o conclu√≠da!\")\n",
        "\n",
        "# Para uso direto com o gerador de artigos\n",
        "if __name__ == \"__main__\":\n",
        "    if IN_COLAB:\n",
        "        print(\"Detectado ambiente Google Colab.\")\n",
        "        print(\"Para configurar suas chaves API de forma segura, execute a fun√ß√£o setup_api_keys() primeiro.\")\n",
        "\n",
        "    run_blog_article_generator()"
      ]
    }
  ]
}